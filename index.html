<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="icon" href="https://cdn.jsdelivr.net/gh/twitter/twemoji@14.0.2/assets/svg/2728.svg" type="image/svg+xml">
  <title>Forth AI</title>
  <meta name="description" content="Research and build AI-native enterprise systems." />
  <style>
    :root{
      --bg-primary: #0a0a0c;
      --bg-secondary: #111114;
      --bg-tertiary: #18181c;
      --bg-elevated: #1f1f24;
      --border-subtle: rgba(255, 255, 255, 0.06);
      --border-default: rgba(255, 255, 255, 0.1);
      --text-primary: #fafafa;
      --text-secondary: #a1a1aa;
      --text-muted: #71717a;
      --accent: #f59e0b;
      --accent-soft: rgba(245, 158, 11, 0.15);
      --maxw: 1100px;
      --radius: 12px;
      --radius-lg: 16px;
      --radius-xl: 20px;
    }

    * { box-sizing: border-box; }
    html, body { height: 100%; }

    body{
      margin: 0;
      font-family: -apple-system, ui-sans-serif, system-ui, sans-serif;
      color: var(--text-primary);
      background: var(--bg-primary);
      -webkit-font-smoothing: antialiased;
      text-rendering: optimizeLegibility;
      min-height: 100dvh;
      display: flex;
      flex-direction: column;
      font-size: 15px;
    }

    a { color: inherit; text-decoration: none; }

    /* Subtle noise texture */
    body::before {
      content: "";
      position: fixed;
      inset: 0;
      pointer-events: none;
      opacity: 0.015;
      background-image: url("data:image/svg+xml,%3Csvg viewBox='0 0 256 256' xmlns='http://www.w3.org/2000/svg'%3E%3Cfilter id='noise'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='0.9' numOctaves='4' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='100%25' height='100%25' filter='url(%23noise)'/%3E%3C/svg%3E");
      z-index: 9999;
    }

    .wrap{
      position: relative;
      flex: 1 0 auto;
      overflow: clip;
    }

    .backdrop{
      position: absolute;
      inset: 0;
      overflow: hidden;
    }

    .backdrop::before{
      content: "";
      position: absolute;
      inset: -2px;
      background:
        radial-gradient(ellipse at 50% 0%, rgba(245,158,11,0.06), rgba(245,158,11,0) 50%),
        repeating-linear-gradient(to right, rgba(255,255,255,0.015) 0 1px, transparent 1px 60px),
        repeating-linear-gradient(to bottom, rgba(255,255,255,0.015) 0 1px, transparent 1px 60px);
      opacity: .5;
    }

    /* Hero graphic - simple illustrative style */
    .hero-graphic {
      position: absolute;
      top: 50%;
      right: 8%;
      transform: translateY(-50%);
      width: min(450px, 32vw);
      height: min(450px, 32vw);
      pointer-events: none;
      z-index: 0;
      opacity: 0;
      animation: fadeInGraphic 1s ease-out 0.8s forwards;
    }

    @keyframes fadeInGraphic {
      to {
        opacity: 1;
      }
    }

    .hero-graphic svg {
      width: 100%;
      height: 100%;
    }

    /* Foundation strokes (AI as base layer) */
    .hero-graphic .foundation {
      stroke: var(--accent);
      stroke-width: 10;
      stroke-linecap: round;
      fill: none;
      opacity: 0;
      animation: drawFoundation 1s ease-out 1s forwards;
    }

    .foundation:nth-child(1) { animation-delay: 1s; }
    .foundation:nth-child(2) { animation-delay: 1.1s; }

    @keyframes drawFoundation {
      to {
        opacity: 0.95;
      }
    }

    /* Building blocks (AI-native systems) */
    .hero-graphic .building-block {
      fill: none;
      stroke: var(--accent);
      stroke-width: 6;
      opacity: 0;
      animation: riseUp 0.8s ease-out forwards;
    }

    .building-block:nth-child(3) { animation-delay: 1.3s; }
    .building-block:nth-child(4) { animation-delay: 1.4s; }
    .building-block:nth-child(5) { animation-delay: 1.5s; }

    @keyframes riseUp {
      from {
        opacity: 0;
        transform: translateY(20px);
      }
      to {
        opacity: 0.85;
        transform: translateY(0);
      }
    }

    /* Interconnection dots */
    .hero-graphic .accent-dot {
      fill: var(--accent);
      opacity: 0;
      animation: fadeInDot 0.4s ease-out forwards;
    }

    .accent-dot:nth-child(6) { animation-delay: 1.6s; }
    .accent-dot:nth-child(7) { animation-delay: 1.7s; }
    .accent-dot:nth-child(8) { animation-delay: 1.8s; }

    @keyframes fadeInDot {
      to {
        opacity: 1;
      }
    }

    /* Connection line */
    .hero-graphic .connection-line {
      stroke: var(--accent);
      stroke-width: 3;
      stroke-linecap: round;
      fill: none;
      opacity: 0;
      stroke-dasharray: 300;
      stroke-dashoffset: 300;
      animation: drawConnection 1.2s ease-out 1.9s forwards;
    }

    @keyframes drawConnection {
      to {
        opacity: 0.6;
        stroke-dashoffset: 0;
      }
    }

    /* Text reveal animations */
    .reveal-text {
      opacity: 0;
      transform: translateY(20px);
      animation: revealUp 0.8s ease-out forwards;
    }

    .reveal-text.delay-1 { animation-delay: 0.2s; }
    .reveal-text.delay-2 { animation-delay: 0.4s; }
    .reveal-text.delay-3 { animation-delay: 0.6s; }
    .reveal-text.delay-4 { animation-delay: 0.8s; }

    @keyframes revealUp {
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    /* Reduce motion support */
    @media (prefers-reduced-motion: reduce) {
      .hero-graphic,
      .network-node,
      .network-line,
      .orbit-ring,
      .reveal-text {
        animation: none !important;
        opacity: 1 !important;
        transform: none !important;
      }
    }

    /* Hide graphic on mobile for performance */
    @media (max-width: 768px) {
      .hero-graphic {
        display: none;
      }
    }

    .hero{
      position: relative;
      z-index: 1;
      width: min(90vw, var(--maxw));
      margin: 0 auto;
      padding: clamp(100px, 14vh, 180px) 0 clamp(80px, 12vh, 140px);
      text-align: center;
    }

    .brand{
      display: inline-flex;
      align-items: center;
      gap: 8px;
      margin-bottom: 48px;
      padding: 4px 12px;
      border-radius: 999px;
      font-size: 13px;
      color: var(--text-muted);
      font-weight: 500;
      letter-spacing: 0.5px;
    }

    .dot{
      width: 6px;
      height: 6px;
      border-radius: 50%;
      background: var(--accent);
      opacity: 0.8;
      animation: pulse 2s ease-in-out infinite;
    }

    @keyframes pulse {
      0%, 100% { opacity: 0.8; }
      50% { opacity: 0.4; }
    }

    h1{
      margin: 0 0 28px;
      font-weight: 600;
      line-height: 1.12;
      letter-spacing: -0.03em;
      font-size: clamp(42px, 7vw, 72px);
      color: var(--text-primary);
      max-width: 800px;
      margin-inline: auto;
    }

    .lead{
      margin: 0 auto 24px;
      max-width: 680px;
      color: var(--text-secondary);
      font-size: clamp(17px, 2.2vw, 20px);
      line-height: 1.6;
      font-weight: 400;
    }

    .nuance{
      margin: 0 auto 48px;
      max-width: 720px;
      color: var(--text-muted);
      font-size: clamp(15px, 2vw, 17px);
      line-height: 1.65;
      font-weight: 400;
      font-style: italic;
    }

    .cta{
      display: inline-flex;
      align-items: center;
      gap: 8px;
      padding: 13px 28px;
      border-radius: 10px;
      background: var(--bg-elevated);
      border: 1px solid var(--border-default);
      color: var(--text-primary);
      font-weight: 500;
      font-size: 15px;
      transition: all 0.2s ease;
      cursor: pointer;
    }

    .cta:hover{
      background: var(--bg-tertiary);
      transform: translateY(-1px);
    }

    .section{
      position: relative;
      z-index: 1;
      width: min(90vw, var(--maxw));
      margin: 0 auto;
      padding: clamp(80px, 12vh, 120px) 0;
      border-top: 1px solid var(--border-subtle);
    }

    .section-title{
      margin: 0 0 16px;
      font-weight: 600;
      font-size: clamp(24px, 3.5vw, 32px);
      letter-spacing: -0.02em;
      color: var(--text-primary);
    }

    .section-subtitle{
      margin: 0 0 48px;
      max-width: 680px;
      color: var(--text-muted);
      font-size: clamp(15px, 2vw, 17px);
      line-height: 1.65;
    }

    .areas{
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
      gap: 40px;
    }

    .area{
      display: flex;
      flex-direction: column;
      gap: 12px;
      padding: 24px;
      border-radius: var(--radius-lg);
      background: rgba(255, 255, 255, 0.01);
      border: 1px solid var(--border-subtle);
      transition: all 0.3s ease;
    }

    .area:hover{
      background: rgba(255, 255, 255, 0.02);
      border-color: var(--border-default);
      transform: translateY(-2px);
    }

    .area h3{
      margin: 0;
      font-size: 18px;
      font-weight: 600;
      letter-spacing: -0.01em;
      color: var(--text-primary);
    }

    .area p{
      margin: 0;
      color: var(--text-secondary);
      font-size: 15px;
      line-height: 1.65;
    }

    .research-list{
      display: grid;
      gap: 24px;
      margin-top: 32px;
    }

    .paper{
      padding: 24px;
      border-radius: var(--radius-lg);
      background: rgba(255, 255, 255, 0.01);
      border: 1px solid var(--border-subtle);
      transition: all 0.3s ease;
    }

    .paper:hover{
      background: rgba(255, 255, 255, 0.02);
      border-color: var(--border-default);
      transform: translateY(-2px);
    }

    .paper-title{
      margin: 0 0 8px;
      font-size: 16px;
      font-weight: 500;
      color: var(--text-primary);
      line-height: 1.4;
    }

    .paper-authors{
      margin: 0 0 12px;
      font-size: 14px;
      color: var(--text-muted);
      font-style: italic;
    }

    .paper-summary{
      margin: 12px 0 0;
      font-size: 14px;
      color: var(--text-secondary);
      line-height: 1.6;
    }

    .paper-meta{
      margin: 0;
      font-size: 14px;
      color: var(--text-muted);
    }

    .paper-venue{
      color: var(--accent);
      font-weight: 500;
    }

    .contact-section{
      text-align: center;
      padding: 48px 32px;
      border-radius: var(--radius-xl);
      background: var(--bg-elevated);
      border: 1px solid var(--border-subtle);
    }

    .contact-section h3{
      margin: 0 0 12px;
      font-size: clamp(20px, 2.8vw, 24px);
      font-weight: 600;
      letter-spacing: -0.01em;
    }

    .contact-section p{
      margin: 0 auto 28px;
      max-width: 480px;
      color: var(--text-secondary);
      font-size: 16px;
      line-height: 1.6;
    }

    .footer{
      width: 100%;
      border-top: 1px solid var(--border-subtle);
      padding: 40px 20px;
      text-align: center;
      margin-top: auto;
    }

    .footer-inner{
      max-width: var(--maxw);
      margin: 0 auto;
    }

    .footer-brand{
      display: inline-flex;
      align-items: center;
      gap: 8px;
      font-weight: 500;
      font-size: 15px;
      color: var(--text-primary);
      margin-bottom: 12px;
    }

    .copyright{
      font-size: 13px;
      color: var(--text-muted);
    }

    @media (max-width: 768px){
      .areas{
        grid-template-columns: 1fr;
      }
      .artifact {
        display: none;
      }
    }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="backdrop" aria-hidden="true"></div>

    <header class="hero" role="banner">
      <div class="brand reveal-text">
        <span class="dot" aria-hidden="true"></span>
        FORTH AI
      </div>

      <h1 class="reveal-text delay-1">The future of work is&nbsp;AI-native</h1>

      <p class="lead reveal-text delay-2">
        We research workforce transformation, AI safety in production, and build systems that demonstrate what's possible when AI is not a tool but the foundation.
      </p>

      <p class="nuance reveal-text delay-3">
        While no one can predict every outcome of AI-native transformation, we do know that building reliable enterprise systems requires both bold experimentation and deliberate safeguards.
      </p>

      <a class="cta reveal-text delay-4" href="#research">View research</a>
    </header>

    <section class="section" id="focus">
      <h2 class="section-title">Social Missions</h2>
      <p class="section-subtitle">
        Three complementary directions — from how people adapt, to how systems behave, to what becomes possible.
      </p>

      <div class="areas">
        <div class="area">
          <h3>Workforce reskilling</h3>
          <p>How organizations adapt when AI becomes the default. Not just training on tools, but redesigning work around new capabilities.</p>
        </div>

        <div class="area">
          <h3>AI safety in production</h3>
          <p>Methods for building accountable systems that operate reliably at scale. Safety isn't theoretical—it's how we build.</p>
        </div>

        <div class="area">
          <h3>AI-native enterprise</h3>
          <p>Production systems that demonstrate research in practice. Closing the gap between what's possible in demos and what works in deployment.</p>
        </div>
      </div>
    </section>

    <section class="section" id="research">
      <h2 class="section-title">Publications</h2>
      <p class="section-subtitle">
        Recent work on multi-turn dialogue systems, fairness in decision-making, and production-ready AI deployment.
      </p>

      <div class="research-list">
        <article class="paper">
          <h3 class="paper-title">Balancing Accuracy and Efficiency in Multi-Turn Intent Classification for LLM-Powered Dialog Systems in Production</h3>
          <p class="paper-authors">Junhua Liu, Yong Keat Tan, Bin Fu, Kwan Hui Lim</p>
          <p class="paper-meta"><span class="paper-venue">IAAI 2026</span></p>
          <p class="paper-summary">Production dialogue systems face a critical challenge: achieving high accuracy while maintaining low latency at scale. This work introduces Symbol Tuning and C-LARA, two complementary approaches that enable enterprise deployment of LLM-powered intent classification. By simplifying intent representations and using LLMs for synthetic data generation, we show how to fine-tune compact models that match large model performance at a fraction of the computational cost. This demonstrates a practical path toward AI-native enterprise systems that are both intelligent and economically viable.</p>
        </article>

        <article class="paper">
          <h3 class="paper-title">From Intents to Conversations: Generating Intent-Driven Dialogues with Contrastive Learning for Multi-Turn Classification</h3>
          <p class="paper-authors">Junhua Liu, Yong Keat Tan, Bin Fu, Kwan Hui Lim</p>
          <p class="paper-meta"><span class="paper-venue">CIKM 2025</span></p>
          <p class="paper-summary">Training multi-turn intent classifiers requires extensive conversational data that captures realistic dialogue patterns—a resource that's often scarce or unavailable. We present Chain-of-Intent, which combines Hidden Markov Models with LLMs to generate context-aware dialogues through self-play, alongside MINT-CL for classification with multi-task contrastive learning. This addresses the fundamental data scarcity problem in conversational AI, enabling organizations to build robust dialogue systems even when starting with limited training examples. The approach reflects our belief that AI systems should help create the conditions for their own improvement.</p>
        </article>

        <article class="paper">
          <h3 class="paper-title">Understanding Fairness-Accuracy Trade-offs in Machine Learning Models: Does Promoting Fairness Undermine Performance?</h3>
          <p class="paper-authors">Junhua Liu, Roy Ka-Wei Lee, Kwan Hui Lim</p>
          <p class="paper-meta"><span class="paper-venue">ASONAM 2025</span></p>
          <p class="paper-summary">The conventional wisdom holds that fairness and accuracy exist in tension—improving one degrades the other. Using real university admissions data, we challenge this assumption by introducing a consistency metric that measures decision agreement among ML models and human evaluators from diverse backgrounds. Our findings reveal that ML models exceed human fairness consistency by 14-18%, while maintaining comparable accuracy. This suggests that properly designed AI systems can simultaneously advance both fairness and performance, supporting our mission to build accountable systems that benefit from AI's systematic nature rather than replicating human biases.</p>
        </article>

        <article class="paper">
          <h3 class="paper-title">BGM-HAN: A Hierarchical Attention Network for Accurate and Fair Decision Assessment on Semi-Structured Profiles</h3>
          <p class="paper-authors">Junhua Liu, Roy Ka-Wei Lee, Kwan Hui Lim</p>
          <p class="paper-meta"><span class="paper-venue">ASONAM 2025</span></p>
          <p class="paper-summary">High-stakes decisions like university admissions involve semi-structured data—a mix of quantitative metrics and qualitative narratives that resist standard ML approaches. BGM-HAN combines Byte-Pair Encoding with gated multi-head hierarchical attention to capture multi-level representations essential for nuanced assessment. Achieving an F1-score of 0.8453, it outperforms both traditional ML and large language model baselines while offering interpretability—a critical requirement when decisions affect people's lives. This work demonstrates how specialized architectures can handle the complexity of real-world decision-making while maintaining transparency and fairness.</p>
        </article>

        <article class="paper">
          <h3 class="paper-title">LARA: Linguistic-Adaptive Retrieval-Augmentation for Multi-Turn Intent Classification</h3>
          <p class="paper-authors">Junhua Liu, Yong Keat Tan, Bin Fu, Kwan Hui Lim</p>
          <p class="paper-meta"><span class="paper-venue">EMNLP 2024</span> (Industry Track)</p>
          <p class="paper-summary">Enterprise chatbots must handle conversations across multiple languages while managing hundreds of distinct intents—a combination that strains traditional approaches. LARA combines a fine-tuned compact model with retrieval-augmented LLM architecture, dynamically leveraging past dialogues and relevant intents to improve contextual understanding. Achieving 3.67% accuracy improvement over state-of-the-art baselines across six languages, it demonstrates how retrieval mechanisms can enhance cross-lingual capabilities without extensive retraining. This represents a step toward truly global AI systems that maintain performance across linguistic boundaries while remaining deployable at scale.</p>
        </article>
      </div>

      <div style="margin-top: 40px;">
        <a class="cta" href="https://scholar.google.com/citations?user=WV190vsAAAAJ" target="_blank" rel="noopener">All publications</a>
      </div>
    </section>

    <section class="section">
      <div class="contact-section">
        <h3>Get in touch</h3>
        <p>Research collaboration, corporate training, or exploring our work.</p>
        <a class="cta" href="mailto:hello@forth.ai">hello@forth.ai</a>
      </div>
    </section>
  </div>

  <footer class="footer">
    <div class="footer-inner">
      <div class="footer-brand">
        <span class="dot" aria-hidden="true"></span>
        Forth AI
      </div>
      <div class="copyright">© 2025 Forth AI</div>
    </div>
  </footer>
</body>
</html>
